{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIS Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importere biblioteker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/ais_train.csv', sep='|')\n",
    "test_df = pd.read_csv('data/ais_test.csv')\n",
    "\n",
    "ports_df = pd.read_csv('data/ports.csv', sep='|')  \n",
    "schedule_df = pd.read_csv('data/schedules_to_may_2024.csv', sep='|')\n",
    "vessels_df = pd.read_csv('data/vessels.csv', sep='|')\n",
    "\n",
    "vessel0 = train_df['vesselId'][0]\n",
    "original_train_df = train_df.copy(deep = True)\n",
    "original_test_df = test_df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-prosessering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>etaRaw_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.74370</td>\n",
       "      <td>-57.85130</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>773975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>8.89440</td>\n",
       "      <td>-79.47939</td>\n",
       "      <td>198</td>\n",
       "      <td>674</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31435175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>39.19065</td>\n",
       "      <td>-76.47567</td>\n",
       "      <td>450</td>\n",
       "      <td>353</td>\n",
       "      <td>80.0</td>\n",
       "      <td>118775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.41189</td>\n",
       "      <td>151.02067</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>166.0</td>\n",
       "      <td>31607975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>35.88379</td>\n",
       "      <td>-5.91636</td>\n",
       "      <td>370</td>\n",
       "      <td>605</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2116775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cog   sog  rot  heading  navstat  latitude  longitude  vesselId  portId  \\\n",
       "0  284.0   0.7    0       88        0 -34.74370  -57.85130        51      40   \n",
       "1  109.6   0.0   -6      347        1   8.89440  -79.47939       198     674   \n",
       "2  111.0  11.0    0      112        0  39.19065  -76.47567       450     353   \n",
       "3   96.4   0.0    0      142        1 -34.41189  151.02067       114      18   \n",
       "4  214.0  19.7    0      215        0  35.88379   -5.91636       370     605   \n",
       "\n",
       "   time_numeric  etaRaw_numeric  \n",
       "0           0.0        773975.0  \n",
       "1          11.0      31435175.0  \n",
       "2          80.0        118775.0  \n",
       "3         166.0      31607975.0  \n",
       "4         206.0       2116775.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/ais_train.csv', sep='|')\n",
    "test_df = pd.read_csv('data/ais_test.csv')\n",
    "\n",
    "ports_df = pd.read_csv('data/ports.csv', sep='|')  \n",
    "schedule_df = pd.read_csv('data/schedules_to_may_2024.csv', sep='|')\n",
    "vessels_df = pd.read_csv('data/vessels.csv', sep='|')\n",
    "\n",
    "original_train_df = train_df.copy(deep = True)\n",
    "original_test_df = test_df.copy(deep = True)\n",
    "\n",
    "# Convert 'time' to datetime\n",
    "train_df['time'] = pd.to_datetime(train_df['time'])\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "# Ensure 'vesselId' is string\n",
    "train_df['vesselId'] = train_df['vesselId'].astype(str)\n",
    "test_df['vesselId'] = test_df['vesselId'].astype(str)\n",
    "\n",
    "# Convert 'time' to numeric format\n",
    "train_df['time_numeric'] = (train_df['time'] - train_df['time'].min()).dt.total_seconds()\n",
    "test_df['time_numeric'] = (test_df['time'] - train_df['time'].min()).dt.total_seconds()\n",
    "\n",
    "# Convert 'portId' to numeric format\n",
    "le = LabelEncoder()\n",
    "le.fit(train_df['portId'])\n",
    "train_df['portId'] = le.transform(train_df['portId'])\n",
    "\n",
    "# Convert 'vesselId' to numeric format\n",
    "le_vesselId = LabelEncoder()\n",
    "le_vesselId.fit(vessels_df['vesselId'])\n",
    "train_df['vesselId'] = le_vesselId.transform(train_df['vesselId'])\n",
    "test_df['vesselId'] = le_vesselId.transform(test_df['vesselId']) \n",
    "vessels_df['vesselId'] = le_vesselId.transform(vessels_df['vesselId'])\n",
    "\n",
    "#Convert shippingline ID to numeric format\n",
    "le_shippingLineId = LabelEncoder()\n",
    "le_shippingLineId.fit(vessels_df['shippingLineId'])\n",
    "vessels_df['shippingLineId'] = le_shippingLineId.transform(vessels_df['shippingLineId'])\n",
    "\n",
    "#Convert homeport to numeric format\n",
    "le_homePort = LabelEncoder()\n",
    "le_homePort.fit(vessels_df['homePort'])\n",
    "vessels_df['homePort'] = le_homePort.transform(vessels_df['homePort'])\n",
    "\n",
    "\n",
    "#Add etaRaw to train_df\n",
    "train_df['etaRaw'] = train_df['etaRaw'].dropna()\n",
    "train_df['etaRaw'] = pd.to_datetime(train_df['etaRaw'], format='%m-%d %H:%M', errors='coerce')\n",
    "train_df['etaRaw'] = train_df['etaRaw'].apply(lambda x: x.replace(year=2024) if pd.notnull(x) else x)\n",
    "train_df['etaRaw_numeric'] = (train_df['etaRaw'] - train_df['time'].min()).dt.total_seconds()\n",
    "\n",
    "# drop etaRaw og time\n",
    "train_df = train_df.drop(columns=['etaRaw', 'time'])\n",
    "\n",
    "# Drop Nan values\n",
    "train_df = train_df.dropna() \n",
    "\n",
    "\n",
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in missing values in each column with the median of the column\n",
    "for column in vessels_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    median_value = vessels_df[column].median()\n",
    "    vessels_df[column].fillna(median_value, inplace=True)\n",
    "\n",
    "\n",
    "vessels_df.to_csv('cleaned_vessels_df.csv', index=False)\n",
    "\n",
    "new_test_df = pd.merge(test_df, vessels_df, on='vesselId', how='left')\n",
    "\n",
    "#display(new_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models for vessels: 100%|██████████| 688/688 [02:24<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "# Fit linear regression models for each vessel\n",
    "lat_models = {}\n",
    "lon_models = {}\n",
    "\n",
    "# Get unique vessel IDs from the training DataFrame\n",
    "vessels = train_df['vesselId'].unique()\n",
    "\n",
    "for vessel in tqdm(vessels, desc=\"Fitting models for vessels\"):\n",
    "    # Filter the training data for the current vessel and merge with vessel information\n",
    "    vessel_data = pd.merge(train_df[train_df['vesselId'] == vessel][['time_numeric', 'vesselId', 'latitude','longitude']], vessels_df, how='left', on='vesselId')\n",
    "    if len(vessel_data) < 2:\n",
    "        continue  # Skip if there's not enough data for fitting\n",
    "    \n",
    "    X = vessel_data.drop(['latitude', 'longitude'], axis=1)\n",
    "    y_lat = vessel_data['latitude']\n",
    "    y_lon = vessel_data['longitude']\n",
    "    \n",
    "    # Fit the models for latitude and longitude\n",
    "    lat_model = xgb.XGBRegressor().fit(X, y_lat)\n",
    "    lon_model = xgb.XGBRegressor().fit(X, y_lon)\n",
    "    \n",
    "    # Store the models for future predictions\n",
    "    lat_models[vessel] = lat_model\n",
    "    lon_models[vessel] = lon_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sog</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.14647</td>\n",
       "      <td>-81.49789</td>\n",
       "      <td>11059371.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sog  latitude  longitude  time_numeric\n",
       "0  0.0  31.14647  -81.49789    11059371.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['time_numeric'] ['sog', 'latitude', 'longitude', 'time_numeric']\ntraining data did not have the following fields: sog, latitude, longitude",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m lat_model \u001b[38;5;241m=\u001b[39m lat_models[vessel]\n\u001b[0;32m     22\u001b[0m lon_model \u001b[38;5;241m=\u001b[39m lon_models[vessel]\n\u001b[1;32m---> 23\u001b[0m lat_prediction \u001b[38;5;241m=\u001b[39m lat_model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     24\u001b[0m lon_prediction \u001b[38;5;241m=\u001b[39m lon_model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\peder\\anaconda345\\Lib\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1187\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1188\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1189\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1190\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1191\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1192\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1193\u001b[0m         )\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peder\\anaconda345\\Lib\\site-packages\\xgboost\\core.py:2510\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2508\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2510\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fns)\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2512\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\Users\\peder\\anaconda345\\Lib\\site-packages\\xgboost\\core.py:3075\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3070\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3071\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3072\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3073\u001b[0m     )\n\u001b[1;32m-> 3075\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['time_numeric'] ['sog', 'latitude', 'longitude', 'time_numeric']\ntraining data did not have the following fields: sog, latitude, longitude"
     ]
    }
   ],
   "source": [
    "# Markus sin\n",
    "lat_pred = []\n",
    "long_pred = []\n",
    "predictions = []\n",
    "last_position = {}\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    vessel = row['vesselId']\n",
    "    time_numeric = row['time_numeric']\n",
    "    if(vessel in last_position):\n",
    "        sog,lat,long = last_position[vessel]\n",
    "    else: \n",
    "        long = np.array(train_df[train_df['vesselId']  == vessel]['longitude'])[-1]\n",
    "        lat = np.array(train_df[train_df['vesselId']  == vessel]['latitude'])[-1]\n",
    "        sog = np.array(train_df[train_df['vesselId']  == vessel]['sog'])[-1]\n",
    "\n",
    "    X_data = {'sog': sog, 'latitude':lat, 'longitude':long, 'time_numeric':time_numeric}\n",
    "    X = pd.DataFrame(data = X_data, index = [0])\n",
    "    display(X.head())\n",
    "\n",
    "    lat_model = lat_models[vessel]\n",
    "    lon_model = lon_models[vessel]\n",
    "    lat_prediction = lat_model.predict(X)\n",
    "    lon_prediction = lon_model.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Positions:   0%|          | 0/51739 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['cog', 'sog', 'rot', 'heading', 'navstat', 'latitude', 'longitude', 'vesselId', 'portId', 'time_numeric', 'etaRaw_numeric'] ['time_numeric']\nexpected navstat, etaRaw_numeric, latitude, rot, heading, portId, longitude, sog, vesselId, cog in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert time_numeric to DataFrame with appropriate column name\u001b[39;00m\n\u001b[0;32m     14\u001b[0m time_numeric_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_numeric\u001b[39m\u001b[38;5;124m'\u001b[39m: [time_numeric]})\n\u001b[1;32m---> 16\u001b[0m lat_pred \u001b[38;5;241m=\u001b[39m lat_model\u001b[38;5;241m.\u001b[39mpredict(time_numeric_df)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m lon_pred \u001b[38;5;241m=\u001b[39m lon_model\u001b[38;5;241m.\u001b[39mpredict(time_numeric_df)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m lat_preds\u001b[38;5;241m.\u001b[39mappend(lat_pred)\n",
      "File \u001b[1;32mc:\\Users\\peder\\anaconda345\\Lib\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[0;32m   1187\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1188\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[0;32m   1189\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1190\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1191\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1192\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1193\u001b[0m         )\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\peder\\anaconda345\\Lib\\site-packages\\xgboost\\core.py:2510\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2508\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2510\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fns)\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2512\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\Users\\peder\\anaconda345\\Lib\\site-packages\\xgboost\\core.py:3075\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3070\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3071\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3072\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3073\u001b[0m     )\n\u001b[1;32m-> 3075\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['cog', 'sog', 'rot', 'heading', 'navstat', 'latitude', 'longitude', 'vesselId', 'portId', 'time_numeric', 'etaRaw_numeric'] ['time_numeric']\nexpected navstat, etaRaw_numeric, latitude, rot, heading, portId, longitude, sog, vesselId, cog in input data"
     ]
    }
   ],
   "source": [
    "# Predict positions with a progress bar\n",
    "lat_preds = []\n",
    "lon_preds = []\n",
    "\n",
    "# Wrap the iterrows() loop with tqdm to add a progress bar\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Predicting Positions\"):\n",
    "    vessel = row['vesselId']\n",
    "    time_numeric = row['time_numeric']\n",
    "    \n",
    "    lat_model = lat_models[vessel]\n",
    "    lon_model = lon_models[vessel]\n",
    "    \n",
    "    # Convert time_numeric to DataFrame with appropriate column name\n",
    "    time_numeric_df = pd.DataFrame({'time_numeric': [time_numeric]})\n",
    "    \n",
    "    lat_pred = lat_model.predict(time_numeric_df)[0]\n",
    "    lon_pred = lon_model.predict(time_numeric_df)[0]\n",
    "    \n",
    "    lat_preds.append(lat_pred)\n",
    "    lon_preds.append(lon_pred)\n",
    "\n",
    "# Store predictions in test_df\n",
    "test_df['latitude_predicted'] = lat_preds\n",
    "test_df['longitude_predicted'] = lon_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ID  longitude_predicted  latitude_predicted\n",
    "0   0           -13.511171           41.366013\n",
    "1   1           -17.383448           19.439676\n",
    "2   2            -3.541152           34.733105\n",
    "3   3            71.226295            5.466014\n",
    "4   4            -9.340018           48.589073"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksporter til csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Få den jævla \"predictions.csv\" filen inn på Kaggle og se om det funker\n"
     ]
    }
   ],
   "source": [
    "submission = test_df[['ID', 'longitude_predicted', 'latitude_predicted']].copy()\n",
    "submission.to_csv('predictions.csv', index=False)\n",
    "print('Få den jævla \"predictions.csv\" filen inn på Kaggle og se om det funker')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

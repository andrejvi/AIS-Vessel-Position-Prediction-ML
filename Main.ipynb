{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIS Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importere biblioteker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from haversine import haversine, Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/ais_train.csv', sep='|')\n",
    "test_df = pd.read_csv('data/ais_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-prosessering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' to datetime\n",
    "train_df['time'] = pd.to_datetime(train_df['time'])\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "# Ensure 'vesselId' is string\n",
    "train_df['vesselId'] = train_df['vesselId'].astype(str)\n",
    "test_df['vesselId'] = test_df['vesselId'].astype(str)\n",
    "\n",
    "# Convert 'time' to numeric format\n",
    "train_df['time_numeric'] = (train_df['time'] - train_df['time'].min()).dt.total_seconds()\n",
    "test_df['time_numeric'] = (test_df['time'] - train_df['time'].min()).dt.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract initial positions\n",
    "initial_positions = train_df.groupby('vesselId').first().reset_index()[['vesselId', 'time', 'latitude', 'longitude']]\n",
    "initial_positions.rename(columns={'time': 'initial_time', 'latitude': 'initial_latitude', 'longitude': 'initial_longitude'}, inplace=True)\n",
    "test_df = test_df.merge(initial_positions, on='vesselId', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression models for each vessel\n",
    "lat_models = {}\n",
    "lon_models = {}\n",
    "\n",
    "vessels = train_df['vesselId'].unique()\n",
    "for vessel in vessels:\n",
    "    vessel_data = train_df[train_df['vesselId'] == vessel]\n",
    "    \n",
    "    if len(vessel_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    X = vessel_data[['time_numeric']]\n",
    "    y_lat = vessel_data['latitude']\n",
    "    y_lon = vessel_data['longitude']\n",
    "    \n",
    "    lat_model = LinearRegression().fit(X, y_lat)\n",
    "    lon_model = LinearRegression().fit(X, y_lon)\n",
    "    \n",
    "    lat_models[vessel] = lat_model\n",
    "    lon_models[vessel] = lon_model\n",
    "\n",
    "# Handle vessels not in training data\n",
    "vessels_in_train = set(lat_models.keys())\n",
    "vessels_in_test = set(test_df['vesselId'].unique())\n",
    "vessels_not_in_train = vessels_in_test - vessels_in_train\n",
    "\n",
    "# Global models\n",
    "global_lat_model = LinearRegression().fit(train_df[['time_numeric']], train_df['latitude'])\n",
    "global_lon_model = LinearRegression().fit(train_df[['time_numeric']], train_df['longitude'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict positions\n",
    "lat_preds = []\n",
    "lon_preds = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    vessel = row['vesselId']\n",
    "    time_numeric = row['time_numeric']\n",
    "    \n",
    "    if vessel in lat_models:\n",
    "        lat_model = lat_models[vessel]\n",
    "        lon_model = lon_models[vessel]\n",
    "    else:\n",
    "        lat_model = global_lat_model\n",
    "        lon_model = global_lon_model\n",
    "    \n",
    "    # Convert time_numeric to DataFrame with appropriate column name\n",
    "    time_numeric_df = pd.DataFrame({'time_numeric': [time_numeric]})\n",
    "    \n",
    "    lat_pred = lat_model.predict(time_numeric_df)[0]\n",
    "    lon_pred = lon_model.predict(time_numeric_df)[0]\n",
    "    \n",
    "    lat_preds.append(lat_pred)\n",
    "    lon_preds.append(lon_pred)\n",
    "\n",
    "test_df['latitude_predicted'] = lat_preds\n",
    "test_df['longitude_predicted'] = lon_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksporter til csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Få den jævla \"predictions.csv\" filen inn på Kaggle og se om det funker\n"
     ]
    }
   ],
   "source": [
    "submission = test_df[['ID', 'longitude_predicted', 'latitude_predicted']].copy()\n",
    "submission.to_csv('predictions.csv', index=False)\n",
    "print('Få den jævla \"predictions.csv\" filen inn på Kaggle og se om det funker')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
